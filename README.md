# Drone_Control_Using_Poses with Python

**YouTube Link:** https://youtu.be/YkIxwt4Gaac?si=0EzKFxkkCyIZwvwE

This project constitutes the **Final Degree Project (TFG)** in Telecommunication Systems Engineering. The main objective was to develop a control system for a drone using **pose recognition** captured through a camera, whether through hand gestures, body positions, or limb movements.

The project was based on detecting key points of the human body. By using advanced algorithms and **Big Data** scripts, it was possible to accurately identify the hands and body of any person in various situations. This enabled the programming of a system that compares the position of the key points and determines the specific pose, triggering different drone movements based on the detected gestures.

Additionally, the project included interactive elements, such as an on-screen scoring system that updated in **real-time** based on interactions with the drone. To enrich the user experience, sound effects and music were also incorporated, adding a playful and immersive component to controlling the drone.

This work not only represented a technical challenge by combining computer vision, Python programming, and telecommunications, but it also explored the possibilities of human-machine interaction, applying innovative technologies in a dynamic and creative environment.
