# Drone_Control_Using_Poses with Python

**YouTube Link:** https://youtu.be/Uu_Br9ynfZw    Este proyecto no solo permitió alcanzar los objetivos técnicos propuestos, sino que también marcó un significativo aprendizaje personal y académico en varias áreas clave. Entre los objetivos logrados destacan:
1.	Adquisición de habilidades en Python: Como primera experiencia en programación con este lenguaje, el proyecto permitió adquirir una comprensión sólida de su sintaxis, estructuras y herramientas, lo que fue clave para desarrollar los algoritmos necesarios.
2.	Comprensión del funcionamiento de los drones: Se profundizó en la estructura operativa y el sistema de control de los drones, entendiendo cómo interactúan con señales externas y cómo pueden responder dinámicamente a comandos basados en datos de sensores y análisis visual.
3.	Implementación de algoritmos de visión por computadora: Se logró comprender y aplicar scripts avanzados para la detección de puntos clave del cuerpo humano, integrando técnicas de análisis de datos y procesamiento visual en tiempo real.
4.	Diseño e integración de sistemas interactivos: Se desarrolló una interfaz interactiva que combinó la interacción física (gestos y poses) con elementos visuales y auditivos, como puntuaciones en pantalla y música, mejorando la experiencia del usuario.
5.	Desarrollo de competencias en Big Data y procesamiento en tiempo real: El uso de algoritmos para analizar y procesar grandes volúmenes de datos visuales en diversas condiciones permitió una mejor comprensión de estas tecnologías y su aplicación práctica.
6.	Resolución de problemas en entornos dinámicos: El proyecto fomentó el desarrollo de habilidades de resolución de problemas, enfrentando retos como la detección precisa en diferentes condiciones de luz, posiciones y variabilidad entre usuarios.
Este trabajo fue una experiencia enriquecedora, no solo desde el punto de vista técnico, sino también en términos de aprendizaje interdisciplinario, combinando conocimientos de telecomunicaciones, programación y visión artificial para desarrollar un sistema funcional, interactivo e innovador.


This project constitutes the **Final Degree Project (TFG)** in Telecommunication Systems Engineering. The main objective was to develop a control system for a drone using **pose recognition** captured through a camera, whether through hand gestures, body positions, or limb movements.

The project was based on detecting key points of the human body. By using advanced algorithms and **Big Data** scripts, it was possible to accurately identify the hands and body of any person in various situations. This enabled the programming of a system that compares the position of the key points and determines the specific pose, triggering different drone movements based on the detected gestures.

Additionally, the project included interactive elements, such as an on-screen scoring system that updated in **real-time** based on interactions with the drone. To enrich the user experience, sound effects and music were also incorporated, adding a playful and immersive component to controlling the drone.

This work not only represented a technical challenge by combining computer vision, Python programming, and telecommunications, but it also explored the possibilities of human-machine interaction, applying innovative technologies in a dynamic and creative environment.
